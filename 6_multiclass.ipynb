{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216694c2",
   "metadata": {},
   "source": [
    "# 8. Create a Neural network architecture from scratch in Python and use it to do multi-class classification on any data.Parameters to be considered while creating the neural network from scratch are specified as:\n",
    "## (1) No of hidden layers : 1 or more\n",
    "## (2) No. of neurons in hidden layer: 100\n",
    "## (3) Non-linearity in the layer : Relu\n",
    "## (4) Use more than 1 neuron in the output layer. \n",
    "## Use a suitable threshold valueUse appropriate Optimisation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45737f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977d8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_network:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.bias1=0\n",
    "        self.bias2=0\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def relu_prime(self, x):\n",
    "        return ( x > 0 ) * 1\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.a1 = np.dot(inputs, self.W1)+self.bias1\n",
    "        self.z1 = self.relu(self.a1)\n",
    "        self.a2 = np.dot(self.z1, self.W2)+self.bias2\n",
    "        z2 = self.sigmoid(self.a2)\n",
    "        \n",
    "        return z2\n",
    "    \n",
    "    def backward(self, x , y ,z2):\n",
    "        error2 = z2 - y \n",
    "        dw2 = np.dot(self.a1.T, error2)\n",
    "        error1 = np.dot(error2, self.W2.T) * self.relu_prime(self.z1)\n",
    "        dw1 = np.dot(x.T, error1)\n",
    "        \n",
    "        self.W1 -= self.learning_rate * dw1\n",
    "        self.W2 -= self.learning_rate * dw2\n",
    "        \n",
    "#         self.bias1+=np.sum(dw1)\n",
    "#         self.bias2+=np.sum(dw2)\n",
    "        \n",
    "    def train(self, x, y):\n",
    "        z2 = self.forward(x)\n",
    "        self.backward(x, y, z2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8789e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,0],[1,1],[1,0],[0,1]])\n",
    "y=np.array([[0],[0],[1],[1]])\n",
    "inp_size=x.shape[1]\n",
    "op_size=y.shape[1]\n",
    "hidden_size=4\n",
    "NN=Neural_network(inp_size,hidden_size,op_size,0.1)\n",
    "x.shape[1],y.shape[1]\n",
    "\n",
    "no_epochs = 50000\n",
    "\n",
    "for i in range(no_epochs):\n",
    "    NN.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736d5e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5       ]\n",
      " [0.0018262 ]\n",
      " [0.99818577]\n",
      " [0.99818571]]\n"
     ]
    }
   ],
   "source": [
    "print(NN.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55c7c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atharva\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target.reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "y = encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec3b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578da344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a13bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize \n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 100\n",
    "output_size = 3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d294884",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Neural_network(input_size, hidden_size, output_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6d78959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_epochs = 50000\n",
    "\n",
    "for i in range(no_epochs):\n",
    "    network.train(x_train, y_train)\n",
    "    \n",
    "z2 = network.forward(x_test)\n",
    "prediction = np.argmax(z2, axis = 1)\n",
    "accuracy = np.mean(prediction == np.argmax(y_test, axis = 1))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb339d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e2b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26c9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self,input_size,hidden_layers,hidden_neurons,output_size,learning_rate):\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        self.hidden_layers=hidden_layers\n",
    "        self.learning_rate=learning_rate;\n",
    "        \n",
    "        for i in range(hidden_layers+1):\n",
    "            if i==0:\n",
    "                self.weights.append(np.random.randn(hidden_neurons,input_size))\n",
    "                self.bias.append(np.full((hidden_neurons,1),1))\n",
    "            elif i==hidden_layers:\n",
    "                self.weights.append(np.random.randn(output_size,hidden_neurons))\n",
    "                self.bias.append(np.full((output_size,1),1))\n",
    "            else:\n",
    "                self.weights.append(np.random.randn(hidden_neurons,hidden_neurons))\n",
    "                self.bias.append(np.full((hidden_neurons,1),1))\n",
    "                \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def first_order_sigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        activations=[]\n",
    "        activations.append(x)\n",
    "        for i in range(self.hidden_layers+1):\n",
    "            x=np.dot(self.weights[i],activations[i])+self.bias[i]\n",
    "            activations.append(self.sigmoid(x))\n",
    "        return activations\n",
    "\n",
    "    def backward(self,activations,di,m):\n",
    "        delta=(activations[-1]-di.T) * self.first_order_sigmoid(np.dot(self.weights[-1],activations[-2])+self.bias[-1])\n",
    "        for i in range(self.hidden_layers,-1,-1):\n",
    "            if i==self.hidden_layers:\n",
    "                prev=np.array(self.weights[i])\n",
    "                self.weights[i]=self.weights[i]-(self.learning_rate/m) * np.dot(delta,activations[i].T)\n",
    "                self.bias[i]=self.bias[i]-(self.learning_rate/m) * np.sum(delta,axis=1,keepdims=True)\n",
    "            else:\n",
    "                delta=np.dot(prev.T, delta) * self.first_order_sigmoid(np.dot(self.weights[i], activations[i])+self.bias[i])\n",
    "                prev=np.array(self.weights[i])\n",
    "                self.weights[i]=self.weights[i]-(self.learning_rate/m) * np.dot(delta,activations[i].T)\n",
    "                self.bias[i]=self.bias[i]-(self.learning_rate/m) * np.sum(delta,axis=1,keepdims=True)\n",
    "            \n",
    "    def train(self,x,y,epochs):\n",
    "        for i in range(epochs):\n",
    "            activations=self.forward(x)\n",
    "            m=x.shape[1]\n",
    "            self.backward(activations,y,m)\n",
    "            if(i%1000==0):\n",
    "                print(\"Error at %d epoch : \"%(i),np.sum(activations[-1]-y.T))\n",
    "            \n",
    "    def predict(self,x):\n",
    "        predictions=[]\n",
    "        for input in x:\n",
    "            prediction = self.forward(np.array(input))\n",
    "            predictions.append(prediction[-1])\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc6d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=4\n",
    "hidden_layers=2\n",
    "neurons_in_hidden_layer=5\n",
    "output_size=3\n",
    "learning_rate=0.1\n",
    "\n",
    "model=ANN(input_size,hidden_layers,neurons_in_hidden_layer,output_size,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e9bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Iris_for_Assi_3(B).csv')\n",
    "\n",
    "x = df.drop(['Id','Species'], axis=1)\n",
    "y=df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416d00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,encoded_labels,test_size=0.2,random_state=62)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "labels = np.array(y_train)\n",
    "y_train = to_categorical(labels)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a71c390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.values\n",
    "x_train=np.array(x_train)\n",
    "x_train=x_train.T\n",
    "x_test=x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1310993a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b776d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at 0 epoch :  205.27789758719717\n",
      "Error at 1000 epoch :  8.580837334859082\n",
      "Error at 2000 epoch :  8.971716869425604\n",
      "Error at 3000 epoch :  7.533976235681927\n",
      "Error at 4000 epoch :  6.379644279692261\n",
      "Error at 5000 epoch :  5.559334962391292\n",
      "Error at 6000 epoch :  4.961784851205653\n",
      "Error at 7000 epoch :  4.509919777291434\n",
      "Error at 8000 epoch :  4.1573652428647145\n",
      "Error at 9000 epoch :  3.8762464017035363\n",
      "Error at 10000 epoch :  3.6500579114263343\n",
      "Error at 11000 epoch :  3.470700909990879\n",
      "Error at 12000 epoch :  3.3397543810199055\n",
      "Error at 13000 epoch :  3.278933197595302\n",
      "Error at 14000 epoch :  3.3552189210368457\n",
      "Error at 15000 epoch :  3.5962982771680645\n",
      "Error at 16000 epoch :  3.8672060119298868\n",
      "Error at 17000 epoch :  3.863611087121402\n",
      "Error at 18000 epoch :  3.453962330542028\n",
      "Error at 19000 epoch :  3.5842542063922007\n",
      "Error at 20000 epoch :  4.404748811397414\n",
      "Error at 21000 epoch :  4.224870999767697\n",
      "Error at 22000 epoch :  3.8074881549048376\n",
      "Error at 23000 epoch :  3.2583356994449093\n",
      "Error at 24000 epoch :  2.7968331207278916\n",
      "Error at 25000 epoch :  2.442345575284534\n",
      "Error at 26000 epoch :  2.1660599982437683\n",
      "Error at 27000 epoch :  1.946143822237901\n",
      "Error at 28000 epoch :  1.7682652106142291\n",
      "Error at 29000 epoch :  1.6222407531471355\n",
      "Error at 30000 epoch :  1.5006267863747902\n",
      "Error at 31000 epoch :  1.3979554666504699\n",
      "Error at 32000 epoch :  1.3101912545944374\n",
      "Error at 33000 epoch :  1.2343291927190645\n",
      "Error at 34000 epoch :  1.1681045396637952\n",
      "Error at 35000 epoch :  1.1097868788646414\n",
      "Error at 36000 epoch :  1.0580352481635642\n",
      "Error at 37000 epoch :  1.0117960541507784\n",
      "Error at 38000 epoch :  0.9702305945527013\n",
      "Error at 39000 epoch :  0.9326630328594272\n",
      "Error at 40000 epoch :  0.8985425738923185\n",
      "Error at 41000 epoch :  0.8674155898258258\n",
      "Error at 42000 epoch :  0.838904794303617\n",
      "Error at 43000 epoch :  0.8126934632250922\n",
      "Error at 44000 epoch :  0.7885133019918171\n",
      "Error at 45000 epoch :  0.7661349595162114\n",
      "Error at 46000 epoch :  0.7453604526139849\n",
      "Error at 47000 epoch :  0.7260169283585145\n",
      "Error at 48000 epoch :  0.7079512740647814\n",
      "Error at 49000 epoch :  0.6910250819748354\n",
      "Error at 50000 epoch :  0.6751093575750555\n",
      "Error at 51000 epoch :  0.6600780473864094\n",
      "Error at 52000 epoch :  0.6457987836578918\n",
      "Error at 53000 epoch :  0.6321178731764246\n",
      "Error at 54000 epoch :  0.6188340456244639\n",
      "Error at 55000 epoch :  0.6056528087537325\n",
      "Error at 56000 epoch :  0.5921306431828646\n",
      "Error at 57000 epoch :  0.5777964498858208\n",
      "Error at 58000 epoch :  0.5629853967714918\n",
      "Error at 59000 epoch :  0.5493771912498234\n",
      "Error at 60000 epoch :  0.5382014956290772\n",
      "Error at 61000 epoch :  0.5292527599390267\n",
      "Error at 62000 epoch :  0.5218237281819753\n",
      "Error at 63000 epoch :  0.5153501482997582\n",
      "Error at 64000 epoch :  0.5094840547743936\n",
      "Error at 65000 epoch :  0.5040228202909978\n",
      "Error at 66000 epoch :  0.4988491375494052\n",
      "Error at 67000 epoch :  0.49389524071442403\n",
      "Error at 68000 epoch :  0.489122352986504\n",
      "Error at 69000 epoch :  0.4845086521174406\n",
      "Error at 70000 epoch :  0.48004211024313276\n",
      "Error at 71000 epoch :  0.47571621799145947\n",
      "Error at 72000 epoch :  0.47152744675770286\n",
      "Error at 73000 epoch :  0.4674737638358994\n",
      "Error at 74000 epoch :  0.4635537834896854\n",
      "Error at 75000 epoch :  0.4597662990785327\n",
      "Error at 76000 epoch :  0.45611004063127986\n",
      "Error at 77000 epoch :  0.4525835633195978\n",
      "Error at 78000 epoch :  0.44918520979839266\n",
      "Error at 79000 epoch :  0.4459131123613299\n",
      "Error at 80000 epoch :  0.4427652148668795\n",
      "Error at 81000 epoch :  0.43973930288585966\n",
      "Error at 82000 epoch :  0.4368330356364391\n",
      "Error at 83000 epoch :  0.43404397631400654\n",
      "Error at 84000 epoch :  0.43136961921073586\n",
      "Error at 85000 epoch :  0.4288074130417038\n",
      "Error at 86000 epoch :  0.42635478045252784\n",
      "Error at 87000 epoch :  0.4240091339764623\n",
      "Error at 88000 epoch :  0.4217678888297119\n",
      "Error at 89000 epoch :  0.41962847297420447\n",
      "Error at 90000 epoch :  0.4175883348586705\n",
      "Error at 91000 epoch :  0.4156449492112069\n",
      "Error at 92000 epoch :  0.4137958212058289\n",
      "Error at 93000 epoch :  0.41203848927441716\n",
      "Error at 94000 epoch :  0.4103705267856749\n",
      "Error at 95000 epoch :  0.408789542770985\n",
      "Error at 96000 epoch :  0.4072931818373171\n",
      "Error at 97000 epoch :  0.40587912337668575\n",
      "Error at 98000 epoch :  0.4045450801576138\n",
      "Error at 99000 epoch :  0.40328879636109505\n"
     ]
    }
   ],
   "source": [
    "epochs=100000\n",
    "model.train(x_train,y_train,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15ee7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.99135830e-04]\n",
      " [1.93414111e-02]\n",
      " [9.81852578e-01]]\n"
     ]
    }
   ],
   "source": [
    "hh=model.forward([[6.7],[3.0],[5.2],[2.3]])\n",
    "print(hh[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78807dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=[]\n",
    "for i in x_test:\n",
    "    test_sample.append([[x] for x in i.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745659cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_sample)\n",
    "y_pred = np.hstack([np.argmax(arr, axis=0) for arr in y_pred]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "148eeee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 2 1 2 0 1 1 2 2 0 1 1 1 0 1 0 0 0 0 2 1 2 0 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6a1203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 2 1 2 0 1 1 2 2 0 1 1 1 0 1 0 0 0 0 2 1 2 0 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43392d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "precision=precision_score(y_test,y_pred,average='weighted')\n",
    "recall=recall_score(y_test,y_pred,average='weighted')\n",
    "f1score=f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054d063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
