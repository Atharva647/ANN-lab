{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faddf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ffa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907872b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,0],[1,1],[1,0],[0,1]])\n",
    "y=np.array([[0],[0],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf27018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=x/np.amax(x,axis=0)\n",
    "# y=y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96260b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca15aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self,inp_size,hidden_size,output_size):\n",
    "        self.inp_size=inp_size\n",
    "        self.output_size=output_size\n",
    "        self.hidden_size=hidden_size \n",
    "#         self.bias1=np.random.uniform(-0.1,0.1,(1,self.hidden_size))\n",
    "#         self.bias2=np.random.uniform(-0.1,0.1,(1,self.output_size))\n",
    "        self.bias1=0\n",
    "        self.bias2=0\n",
    "        self.w1=np.random.uniform(-0.1,0.5,(self.inp_size,self.hidden_size))\n",
    "        self.w2=np.random.uniform(-0.1,0.5,(self.hidden_size,self.output_size))\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self,s):\n",
    "        return s*(1-s)\n",
    "    \n",
    "    def feedforward(self,x):\n",
    "        self.summation=np.dot(x,self.w1)+self.bias1\n",
    "        self.hidden_layer_inp=self.sigmoid(self.summation)\n",
    "        \n",
    "        self.hidden_sum=np.dot(self.hidden_layer_inp,self.w2)+self.bias2\n",
    "        output=self.sigmoid(self.hidden_sum)\n",
    "        return output\n",
    "    \n",
    "    def backpropagation(self,x,y,output,lr):\n",
    "        \n",
    "#         self.error = y - output\n",
    "#         self.output_delta = self.error * self.sigmoid_derivative(output)\n",
    "\n",
    "#         self.hidden_error = np.dot(self.output_delta, self.w2.T)  # Calculate error in the hidden layer\n",
    "#         self.hidden_delta = self.hidden_error * self.sigmoid_derivative(self.hidden_layer_inp)\n",
    "\n",
    "#         self.w1 += np.dot(x.T, self.hidden_delta) * lr\n",
    "#         self.w2 += np.dot(self.hidden_layer_inp.T, self.output_delta) * lr\n",
    "\n",
    "#         self.bias1 += np.sum(self.hidden_delta, axis=0) * lr\n",
    "#         self.bias2 += np.sum(self.output_delta, axis=0) * lr\n",
    "        self.error=y-output\n",
    "        self.output_delta=self.error*self.sigmoid_derivative(output)\n",
    "        \n",
    "        self.hidden_error=self.output_delta.dot(self.w2.T)\n",
    "        self.hidden_delta=self.hidden_error*self.sigmoid_derivative(self.hidden_layer_inp)\n",
    "        \n",
    "        self.w1+=x.T.dot(self.hidden_delta)*lr\n",
    "        self.w2+=self.hidden_layer_inp.T.dot(self.output_delta)*lr\n",
    "        \n",
    "        self.bias1+=np.sum(self.hidden_delta)*lr\n",
    "        self.bias2+=np.sum(self.output_delta)*lr\n",
    "        \n",
    "    def train(self,x,y,epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output=self.feedforward(x)\n",
    "            self.backpropagation(x,y,output,0.1)\n",
    "            if epoch%250==0:\n",
    "                print('loss: ',np.mean(np.square(y-output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb860c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_size=x.shape[1]\n",
    "op_size=y.shape[1]\n",
    "hidden_size=4\n",
    "NN=NeuralNetwork(inp_size,hidden_size,op_size)\n",
    "x.shape[1],y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cecd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2018392955322427\n",
      "loss:  0.1824048241158069\n",
      "loss:  0.1565308786774565\n",
      "loss:  0.12263129825771073\n",
      "loss:  0.08663071966576769\n",
      "loss:  0.05870894096535755\n",
      "loss:  0.04083391426537325\n",
      "loss:  0.029787224579726962\n",
      "loss:  0.022737327421045263\n",
      "loss:  0.018023948870647618\n",
      "loss:  0.014729354083107474\n",
      "loss:  0.012335449511195924\n",
      "loss:  0.010537845634448463\n",
      "loss:  0.009150027315600759\n",
      "loss:  0.008053121907965276\n",
      "loss:  0.007168640717929853\n",
      "loss:  0.0064431100761661855\n",
      "loss:  0.005839077525052709\n",
      "loss:  0.005329663531874453\n",
      "loss:  0.0048951552871605\n",
      "loss:  0.004520815542740329\n",
      "loss:  0.004195436277631637\n",
      "loss:  0.00391036153013172\n",
      "loss:  0.003658813159687327\n",
      "loss:  0.003435416659150474\n",
      "loss:  0.0032358618186332363\n",
      "loss:  0.003056656013108076\n",
      "loss:  0.0028949422121324515\n",
      "loss:  0.0027483629344541402\n",
      "loss:  0.0026149572952583423\n",
      "loss:  0.0024930822107913455\n",
      "loss:  0.002381351457872255\n",
      "loss:  0.002278588082846232\n",
      "loss:  0.002183786898799042\n",
      "loss:  0.0020960846829321316\n",
      "loss:  0.002014736306286689\n",
      "loss:  0.0019390954738490965\n",
      "loss:  0.0018685990770385158\n",
      "loss:  0.0018027543984047148\n",
      "loss:  0.0017411285846403238\n",
      "loss:  0.0016833399358542303\n",
      "loss:  0.001629050658507617\n",
      "loss:  0.00157796080504429\n",
      "loss:  0.0015298031811997526\n",
      "loss:  0.0014843390467038052\n",
      "loss:  0.0014413544698516482\n",
      "loss:  0.0014006572236092267\n",
      "loss:  0.0013620741323184394\n",
      "loss:  0.0013254487950108943\n",
      "loss:  0.0012906396248280616\n",
      "loss:  0.0012575181548431643\n",
      "loss:  0.0012259675692671693\n",
      "loss:  0.0011958814260443766\n",
      "loss:  0.0011671625425483784\n",
      "loss:  0.0011397220207436938\n",
      "loss:  0.00111347839199285\n",
      "loss:  0.0010883568648271654\n",
      "loss:  0.0010642886615921507\n",
      "loss:  0.0010412104320285257\n",
      "loss:  0.001019063733638963\n",
      "loss:  0.0009977945701852924\n",
      "loss:  0.0009773529809132217\n",
      "loss:  0.0009576926741545404\n",
      "loss:  0.0009387706998451199\n",
      "loss:  0.0009205471562480561\n",
      "loss:  0.0009029849268090346\n",
      "loss:  0.0008860494436132846\n",
      "loss:  0.0008697084743764173\n",
      "loss:  0.0008539319302971694\n",
      "loss:  0.0008386916924399046\n",
      "loss:  0.0008239614546064447\n",
      "loss:  0.0008097165809086415\n",
      "loss:  0.0007959339764702591\n",
      "loss:  0.0007825919698751832\n",
      "loss:  0.0007696702061421518\n",
      "loss:  0.0007571495491482028\n",
      "loss:  0.0007450119925469024\n",
      "loss:  0.0007332405783353746\n",
      "loss:  0.0007218193223186543\n",
      "loss:  0.0007107331458028538\n",
      "loss:  0.0006999678129212447\n",
      "loss:  0.0006895098730613977\n",
      "loss:  0.0006793466079179784\n",
      "loss:  0.0006694659827454755\n",
      "loss:  0.0006598566014291536\n",
      "loss:  0.0006505076650316353\n",
      "loss:  0.0006414089335068329\n",
      "loss:  0.000632550690303904\n",
      "loss:  0.0006239237096111073\n",
      "loss:  0.0006155192260137205\n",
      "loss:  0.0006073289063620508\n",
      "loss:  0.0005993448236648001\n",
      "loss:  0.0005915594328405422\n",
      "loss:  0.0005839655481755571\n",
      "loss:  0.0005765563223501173\n",
      "loss:  0.0005693252269081436\n",
      "loss:  0.0005622660340560144\n",
      "loss:  0.0005553727996867351\n",
      "loss:  0.0005486398475348104\n",
      "loss:  0.000542061754375159\n",
      "loss:  0.000535633336187197\n",
      "loss:  0.0005293496352116989\n",
      "loss:  0.000523205907834272\n",
      "loss:  0.000517197613234769\n",
      "loss:  0.000511320402747013\n",
      "loss:  0.0005055701098777045\n",
      "loss:  0.0004999427409375886\n",
      "loss:  0.0004944344662417071\n",
      "loss:  0.000489041611838949\n",
      "loss:  0.0004837606517343384\n",
      "loss:  0.00047858820057024765\n",
      "loss:  0.00047352100673541943\n",
      "loss:  0.00046855594587302693\n",
      "loss:  0.00046369001476114977\n",
      "loss:  0.00045892032554114903\n",
      "loss:  0.00045424410027109494\n",
      "loss:  0.00044965866578328617\n",
      "loss:  0.0004451614488262032\n",
      "loss:  0.000440749971472863\n",
      "loss:  0.00043642184677875317\n",
      "loss:  0.00043217477467367066\n",
      "loss:  0.0004280065380730222\n",
      "loss:  0.0004239149991950531\n",
      "loss:  0.0004198980960714364\n",
      "loss:  0.00041595383923953425\n",
      "loss:  0.00041208030860547364\n",
      "loss:  0.0004082756504678385\n",
      "loss:  0.0004045380746924728\n",
      "loss:  0.00040086585202962554\n",
      "loss:  0.00039725731156514373\n",
      "loss:  0.00039371083829797685\n",
      "loss:  0.0003902248708367805\n",
      "loss:  0.0003867978992089238\n",
      "loss:  0.0003834284627754906\n",
      "loss:  0.00038011514824644603\n",
      "loss:  0.0003768565877903579\n",
      "loss:  0.0003736514572335361\n",
      "loss:  0.0003704984743436505\n",
      "loss:  0.000367396397193323\n",
      "loss:  0.00036434402259934417\n",
      "loss:  0.0003613401846335062\n",
      "loss:  0.000358383753201257\n",
      "loss:  0.0003554736326846439\n",
      "loss:  0.000352608760646127\n",
      "loss:  0.00034978810659016315\n",
      "loss:  0.0003470106707795955\n",
      "loss:  0.0003442754831040046\n",
      "loss:  0.0003415816019974351\n",
      "loss:  0.0003389281134029892\n",
      "loss:  0.0003363141297819426\n",
      "loss:  0.00033373878916518837\n",
      "loss:  0.0003312012542449187\n",
      "loss:  0.0003287007115045472\n",
      "loss:  0.00032623637038506787\n",
      "loss:  0.00032380746248603115\n",
      "loss:  0.00032141324079951194\n",
      "loss:  0.0003190529789754981\n",
      "loss:  0.0003167259706172024\n",
      "loss:  0.00031443152860486604\n",
      "loss:  0.0003121689844467829\n",
      "loss:  0.00030993768765621505\n",
      "loss:  0.00030773700515306746\n",
      "loss:  0.00030556632068911866\n",
      "loss:  0.00030342503429580124\n",
      "loss:  0.00030131256175347856\n",
      "loss:  0.0002992283340812267\n",
      "loss:  0.0002971717970462768\n",
      "loss:  0.00029514241069216135\n",
      "loss:  0.0002931396488848082\n",
      "loss:  0.0002911629988757366\n",
      "loss:  0.00028921196088167197\n",
      "loss:  0.0002872860476798077\n",
      "loss:  0.0002853847842180769\n",
      "loss:  0.0002835077072397744\n",
      "loss:  0.0002816543649219395\n",
      "loss:  0.0002798243165268806\n",
      "loss:  0.00027801713206632725\n",
      "loss:  0.00027623239197767293\n",
      "loss:  0.0002744696868117555\n",
      "loss:  0.0002727286169318037\n",
      "loss:  0.00027100879222296756\n",
      "loss:  0.0002693098318121024\n",
      "loss:  0.0002676313637973311\n",
      "loss:  0.00026597302498699286\n",
      "loss:  0.00026433446064765204\n",
      "loss:  0.000262715324260724\n",
      "loss:  0.00026111527728745566\n",
      "loss:  0.0002595339889418687\n",
      "loss:  0.0002579711359713896\n",
      "loss:  0.000256426402444857\n",
      "loss:  0.0002548994795476087\n",
      "loss:  0.00025339006538338895\n",
      "loss:  0.0002518978647827951\n",
      "loss:  0.0002504225891180614\n",
      "loss:  0.0002489639561238545\n",
      "loss:  0.0002475216897239357\n",
      "loss:  0.00024609551986343664\n",
      "loss:  0.00024468518234650185\n",
      "loss:  0.00024329041867919319\n",
      "loss:  0.00024191097591733113\n",
      "loss:  0.00024054660651923142\n",
      "loss:  0.0002391970682030292\n",
      "loss:  0.00023786212380851428\n",
      "loss:  0.00023654154116327836\n",
      "loss:  0.0002352350929530006\n",
      "loss:  0.0002339425565957711\n",
      "loss:  0.0002326637141202626\n",
      "loss:  0.00023139835204762587\n",
      "loss:  0.00023014626127700592\n",
      "loss:  0.00022890723697449868\n",
      "loss:  0.00022768107846548108\n",
      "loss:  0.000226467589130142\n",
      "loss:  0.0002252665763021712\n",
      "loss:  0.00022407785117043016\n",
      "loss:  0.00022290122868353737\n",
      "loss:  0.00022173652745726804\n",
      "loss:  0.00022058356968466275\n",
      "loss:  0.0002194421810487497\n",
      "loss:  0.00021831219063781184\n",
      "loss:  0.00021719343086309658\n",
      "loss:  0.00021608573737888414\n",
      "loss:  0.00021498894900484527\n",
      "loss:  0.0002139029076506261\n",
      "loss:  0.00021282745824253806\n",
      "loss:  0.000211762448652349\n",
      "loss:  0.00021070772962805153\n",
      "loss:  0.0002096631547265859\n",
      "loss:  0.0002086285802484066\n",
      "loss:  0.00020760386517390804\n",
      "loss:  0.0002065888711015496\n",
      "loss:  0.00020558346218771772\n",
      "loss:  0.00020458750508822247\n",
      "loss:  0.0002036008689013786\n",
      "loss:  0.0002026234251126284\n",
      "loss:  0.0002016550475406776\n",
      "loss:  0.00020069561228506193\n",
      "loss:  0.00019974499767509707\n",
      "loss:  0.00019880308422024032\n",
      "loss:  0.0001978697545617117\n",
      "loss:  0.00019694489342542653\n",
      "loss:  0.0001960283875761565\n",
      "loss:  0.00019512012577288523\n",
      "loss:  0.00019421999872532716\n",
      "loss:  0.00019332789905159204\n",
      "loss:  0.0001924437212369131\n",
      "loss:  0.00019156736159345946\n",
      "loss:  0.00019069871822118234\n",
      "loss:  0.00018983769096963437\n",
      "loss:  0.00018898418140078277\n",
      "loss:  0.0001881380927527613\n",
      "loss:  0.00018729932990451965\n",
      "loss:  0.00018646779934137307\n",
      "loss:  0.0001856434091214202\n",
      "loss:  0.00018482606884277512\n",
      "loss:  0.00018401568961162778\n",
      "loss:  0.0001832121840110986\n",
      "loss:  0.00018241546607083336\n",
      "loss:  0.00018162545123737297\n",
      "loss:  0.0001808420563452277\n",
      "loss:  0.00018006519958865846\n",
      "loss:  0.00017929480049414299\n",
      "loss:  0.00017853077989350648\n",
      "loss:  0.00017777305989769612\n",
      "loss:  0.00017702156387117574\n",
      "loss:  0.0001762762164069464\n",
      "loss:  0.00017553694330215019\n",
      "loss:  0.00017480367153424782\n",
      "loss:  0.0001740763292377644\n",
      "loss:  0.00017335484568157557\n",
      "loss:  0.00017263915124673314\n",
      "loss:  0.0001719291774047874\n",
      "loss:  0.00017122485669664303\n",
      "loss:  0.00017052612271187468\n",
      "loss:  0.00016983291006853458\n",
      "loss:  0.00016914515439341694\n",
      "loss:  0.0001684627923027821\n",
      "loss:  0.00016778576138350108\n",
      "loss:  0.00016711400017465228\n",
      "loss:  0.00016644744814951594\n",
      "loss:  0.0001657860456979781\n",
      "loss:  0.00016512973410933294\n",
      "loss:  0.00016447845555546924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0001638321530744272\n",
      "loss:  0.00016319077055432414\n",
      "loss:  0.00016255425271762775\n",
      "loss:  0.00016192254510579384\n",
      "loss:  0.00016129559406421697\n",
      "loss:  0.00016067334672752957\n",
      "loss:  0.00016005575100521622\n",
      "loss:  0.00015944275556753194\n",
      "loss:  0.00015883430983173536\n",
      "loss:  0.00015823036394861547\n",
      "loss:  0.00015763086878931037\n",
      "loss:  0.00015703577593240327\n",
      "loss:  0.0001564450376512949\n",
      "loss:  0.00015585860690184989\n",
      "loss:  0.00015527643731029104\n",
      "loss:  0.00015469848316137456\n",
      "loss:  0.00015412469938678265\n",
      "loss:  0.00015355504155379173\n",
      "loss:  0.00015298946585414288\n",
      "loss:  0.00015242792909318025\n",
      "loss:  0.00015187038867918703\n",
      "loss:  0.00015131680261295198\n",
      "loss:  0.00015076712947755607\n",
      "loss:  0.00015022132842836423\n",
      "loss:  0.00014967935918321925\n",
      "loss:  0.00014914118201283852\n",
      "loss:  0.00014860675773140797\n",
      "loss:  0.0001480760476873675\n",
      "loss:  0.00014754901375437564\n",
      "loss:  0.00014702561832246241\n",
      "loss:  0.00014650582428936434\n",
      "loss:  0.00014598959505201424\n",
      "loss:  0.00014547689449822794\n",
      "loss:  0.0001449676869985317\n",
      "loss:  0.00014446193739816205\n",
      "loss:  0.00014395961100923687\n",
      "loss:  0.00014346067360304193\n",
      "loss:  0.00014296509140251888\n",
      "loss:  0.00014247283107485888\n",
      "loss:  0.0001419838597242667\n",
      "loss:  0.00014149814488484947\n",
      "loss:  0.00014101565451365582\n",
      "loss:  0.00014053635698383724\n",
      "loss:  0.0001400602210779494\n",
      "loss:  0.00013958721598138072\n",
      "loss:  0.00013911731127590798\n",
      "loss:  0.00013865047693336716\n",
      "loss:  0.000138186683309455\n",
      "loss:  0.0001377259011376386\n",
      "loss:  0.00013726810152319083\n",
      "loss:  0.00013681325593732833\n",
      "loss:  0.00013636133621146507\n",
      "loss:  0.0001359123145315658\n",
      "loss:  0.00013546616343262406\n",
      "loss:  0.0001350228557932151\n",
      "loss:  0.00013458236483017503\n",
      "loss:  0.00013414466409336265\n",
      "loss:  0.00013370972746052504\n",
      "loss:  0.00013327752913225614\n",
      "loss:  0.00013284804362704758\n",
      "loss:  0.00013242124577642945\n",
      "loss:  0.00013199711072019643\n",
      "loss:  0.00013157561390173155\n",
      "loss:  0.00013115673106340334\n",
      "loss:  0.00013074043824204577\n",
      "loss:  0.0001303267117645334\n",
      "loss:  0.00012991552824341625\n",
      "loss:  0.0001295068645726519\n",
      "loss:  0.00012910069792339756\n",
      "loss:  0.0001286970057398913\n",
      "loss:  0.00012829576573539388\n",
      "loss:  0.00012789695588821337\n",
      "loss:  0.00012750055443778841\n",
      "loss:  0.0001271065398808504\n",
      "loss:  0.00012671489096764918\n",
      "loss:  0.00012632558669824304\n",
      "loss:  0.0001259386063188557\n",
      "loss:  0.00012555392931829938\n",
      "loss:  0.00012517153542444828\n",
      "loss:  0.00012479140460079082\n",
      "loss:  0.00012441351704302886\n",
      "loss:  0.00012403785317573245\n",
      "loss:  0.0001236643936490683\n",
      "loss:  0.00012329311933556176\n",
      "loss:  0.00012292401132694064\n",
      "loss:  0.00012255705093100556\n",
      "loss:  0.0001221922196685727\n",
      "loss:  0.00012182949927045747\n",
      "loss:  0.00012146887167451814\n",
      "loss:  0.00012111031902273875\n",
      "loss:  0.00012075382365837274\n",
      "loss:  0.00012039936812311864\n",
      "loss:  0.00012004693515436441\n",
      "loss:  0.0001196965076824532\n",
      "loss:  0.00011934806882801715\n",
      "loss:  0.00011900160189933626\n",
      "loss:  0.00011865709038975723\n",
      "loss:  0.00011831451797514004\n",
      "loss:  0.0001179738685113594\n",
      "loss:  0.00011763512603183451\n",
      "loss:  0.00011729827474511563\n",
      "loss:  0.00011696329903248866\n",
      "loss:  0.00011663018344563748\n",
      "loss:  0.00011629891270433624\n",
      "loss:  0.00011596947169417439\n",
      "loss:  0.00011564184546433118\n",
      "loss:  0.00011531601922536832\n",
      "loss:  0.0001149919783470784\n",
      "loss:  0.00011466970835634997\n",
      "loss:  0.0001143491949350744\n",
      "loss:  0.0001140304239180865\n",
      "loss:  0.00011371338129113982\n",
      "loss:  0.00011339805318890428\n",
      "loss:  0.0001130844258930082\n",
      "loss:  0.00011277248583010179\n",
      "loss:  0.0001124622195699535\n",
      "loss:  0.00011215361382358076\n",
      "loss:  0.00011184665544140014\n"
     ]
    }
   ],
   "source": [
    "NN.train(x,y,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e5be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01298305]\n",
      " [0.00907902]\n",
      " [0.99012124]\n",
      " [0.99012137]]\n"
     ]
    }
   ],
   "source": [
    "print(NN.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd0946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
